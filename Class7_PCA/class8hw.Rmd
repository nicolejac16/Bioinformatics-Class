---
title: "class8"
output:
  pdf_document: default
  html_document: default
name: Nicole Jacobson A13081206
---


## Clustering Methods

Kmeans clustering in R  is done with 'kmeans()' function. You tell it how many clusters you want beforehand


```{r}
#here we are making up some data to learn and test with
# give rnorm n number of points you want, mean, and sd. It will output a random data set
# cbind takes a vector and binds it to another column next to it
# rbind will do the same but add another row
# now the data is clustered into two

tmp <- c(rnorm(30, 3), rnorm(30,-3))
data <- cbind(x=tmp, y=rev(tmp))
plot(data)
```

```{r}
#now we will run kmeans. Set k to 2 and nstart to 20. You have to tell it how many clusters you want
#clustering vector is telling you which cluster each element of data is in
km <- kmeans(data, centers = 2, nstart = 20)
km
```


```{r}
# Q. How many points are in each cluster?
km$size
```

```{r}
# Q What component of your result object details cluster assignment/membership?
km$cluster

```


```{r}
# Q What component of your result object details cluster center?
km$center

```


```{r}
# Q What component of your result object details cluster assignment and add cluster centers as blue points

plot(data, col=km$cluster)
points(km$centers, col="blue", pch=15, cex=2)


```

## Hierarchical Clustering

```{r}
#we will use the 'hclust()' function on the same data as above
# can can't just feed in the previous data set. We need to give it a measure of how similar each point is to each other (dist)
hc <- hclust(dist(data))
hc

```

```{r}
#hclust has a plot method. Here it produced a cluster dendrogram. The numbers at the bottom are what the row names are. The first group is 1-30 and the second is 31-60. The two groups are far away from each other. Now we will cut the tree so we can get the two groups seperated.
plot(hc)
abline(h=8, col="red")

```

```{r}
# to find our membership vector, we need to 'cut' the tree and for this we use the term 'cutree()' function. We input the height (h) where we want to cut based on the graph above.
cutree(hc,h=8)


```

```{r}
# can also cut the tree so you have a distinct number of branches
grps <- cutree(hc,k=2)
```

```{r}
plot(data, col=grps)
```

kmeans(x,centers=?)
hclust(dist(x))


## Principal Component Analysis (PCA)


```{r}
#read in the UK foods data
url <- "https://tinyurl.com/UK-foods"
x <- read.csv(url)
nrow(x)
ncol(x)
#we can see that the food row is supposed to be a column
head(x)
```

```{r}
#this is a destructive way to do this.
rownames(x) <- x[,1]
x <- x[,-1]
x


```


```{r}
# this will note override your data as you go.
x <- read.csv(url, row.names=1)
head(x)

```

# Q2. Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one approach more robust than another under certain circumstances?

  The second method is easier because it stores the command all in one variable. The first method changes every time you run the script, therefore deleting the first row every time leaving you with no data. 

```{r}
# x is not a matrix so we have to force it to be a matrix (as.matrix(x))
barplot(as.matrix(x), beside=T, col=rainbow(17))
```



# Q3. Changing the beside argument to false in barplot() will give the following plot;

```{r}

barplot(as.matrix(x), beside=F, col=rainbow(nrow(x)))
```

# Q5. Generating all pairwise plots may help somewhat. Can you make sense of the following code and resulting figure? What does it mean if a given point lies on the diagonal for a given plot?



```{r}
# pairs is an all pairwise plot. 
# points that fall on the diagonal means the two countries are equal
# this can give you the fold change from one treatment to another
mycols <- rainbow(nrow(x))
pairs(x, col=mycols) 

```

# Q6. What is the main differences between N. Ireland and the other countries of the UK in terms of this data-set?

## PCA to the resue to reduce complication in the data

  Here we will use the base R function for PCA, which is called 'prcomp()'. This function wants the transpose of our data.

```{r}
# it wants the countries in the rows and data in columns. 
# t is used to transpose the data
# we are looking to maximize the proportion of variance the PCs describe. PC1 is decribing over 67% of the variance, and 29% on PC2
pca <-prcomp(t(x))
summary(pca)
```

Now we will make a score/pca plot (pc1 vs pc2)

```{r}
# now we want to make a plot of PC1 vs PC2
# attributes tells us what makes up the pca 
attributes(pca)
```


This is showing us that N. Ireland is eating very different things than Scotland, England, and Wales as explained by PC1.

```{r}
# We are after the pca$x component for this plot
# we are using base r plots for now to quickly visualize the data
plot(pca$x[,1:2])
text(pca$x[,1:2], labels = colnames(x), col=c("red","blue","orange","green"))


```


We can now examine PC1 in depth since it explains the highest percent of the variance

  In N. Ierland they eat way more potatoes and way less fresh fruit.

```{r}
# Let's focus on PC1 as it accounts for > 90% of variance 
par(mar=c(10, 3, 0.35, 0))
barplot( pca$rotation[,1], las=2 )

```

```{r}
biplot(pca)
```

```{r}
# there are 5 wt and 5 knockout
url2 <- "https://tinyurl.com/expression-CSV"
rna.data <- read.csv(url2, row.names=1)
head(rna.data)
```

```{r}
nrow(rna.data)
ncol(rna.data)
colnames(rna.data)
```

```{r}
pca.rna <- prcomp(t(rna.data), scale = TRUE)
summary(pca.rna)

```

```{r}
plot(pca.rna$x[,1:2])
text(pca.rna$x[,1:2], labels = colnames(rna.data))
```

Now we see two groups split along PC1. The WT and KO are separated. We sometimes use this as a quality control to see if your experimental points fall close together. 

# Q10. How many genes and samples do we have in the dataset?
  We have 100 genes and 10 samples

```{r}
# first need to transpose or data before doing the PCA
pca <- prcomp(t(rna.data), scale=TRUE)
summary(pca)
```

```{r}
plot(pca)
```

```{r}
# How much variance is captured by PC
pca.var <- pca$sdev^2

# Percent variance is often more informative 
pca.var.per <- round(pca.var/sum(pca.var)*100, 1)

```

```{r}
barplot(pca.var.per, main="Scree Plot",
names.arg = paste0("PC", 1:10),
xlab="Principal Component", ylab="Percent Variation")
```


```{r}
colvec <- colnames(rna.data)
colvec[grep("wt", colvec)] <- "red"
colvec[grep("ko", colvec)] <- "blue"
plot(pca$x[,1], pca$x[,2], col=colvec, pch=16,
xlab=paste0("PC1 (", pca.var.per[1], "%)"),
ylab=paste0("PC2 (", pca.var.per[2], "%)"))
text(pca$x[,1], pca$x[,2], labels = colnames(rna.data), pos=c(rep(4,5), rep(2,5)))
```

# Now lets try plotting the same data using ggplot 

```{r}
library(ggplot2)
df <- as.data.frame(pca$x)
# Our first basic plot
ggplot(df) +
aes(PC1, PC2) +
geom_point()
```


```{r}
# Add a 'wt' and 'ko' "condition" column
df$samples <- colnames(rna.data)
df$condition <- substr(colnames(rna.data),1,2)
p <- ggplot(df) +
aes(PC1, PC2, label=samples, col=condition) +
geom_label(show.legend = FALSE)
p
```

```{r}
# now we will adjust the theme and add in a primary ane secondary title
p + labs(title="PCA of RNASeq Data",
subtitle = "PC1 clealy seperates wild-type from knock-out samples",
x=paste0("PC1 (", pca.var.per[1], "%)"),
y=paste0("PC2 (", pca.var.per[2], "%)"),
caption="BIMM143 example data") +
theme_bw()
```



